murder_note ="""You may call me heartless, a killer, a monster, a murderer, but I'm still NOTHING compared to the villian that Jay was. This whole contest was
a sham, an elaborate plot to shame the contestants and feed Jay's massive, massive ego. SURE you think you know him! You've seen him
smiling for the cameras, laughing, joking, telling stories, waving his money around like a prop but off camera he was a sinister beast, a cruel
cruel taskmaster, he treated all of us like slaves, like cattle, like animals! Do you remember Lindsay, she was the first to go, he called her such
horrible things that she cried all night, keeping up all up, crying, crying, and more crying, he broke her with his words. I miss my former cast
members, all of them very much. And we had to live with him, live in his home, live in his power, deal with his crazy demands. AND FOR
WHAT! DID YOU KNOW THAT THE PRIZE ISN'T REAL? He never intended to marry one of us! The carrot on the stick was gone, all that was
left was stick, he told us last night that we were all a terrible terrible disappointment and none of us would ever amount to anything, and that
regardless of who won the contest he would never speak to any of us again! It's definitely the things like this you can feel in your gut how
wrong he is! Well I showed him, he got what he deserved all right, I showed him, I showed him the person I am! I wasn't going to be pushed
around any longer, and I wasn't going to let him go on pretending that he was some saint when all he was was a sick sick twisted man who
deserved every bit of what he got. The fans need to know, Jay Stacksby is a vile amalgamation of all things evil and bad and the world is a
better place without him."""

lily_trebuchet_intro ="""Hi, I'm Lily Trebuchet from East Egg, Long Island. I love cats, hiking, and curling up under a warm blanket with a book. So they gave this little
questionnaire to use for our bios so lets get started. What are some of my least favorite household chores? Dishes, oh yes it's definitely the
dishes, I just hate doing them, don't you? Who is your favorite actor and why? Hmm, that's a hard one, but I think recently I'll have to go with
Michael B. Jordan, every bit of that man is handsome, HANDSOME! Do you remember seeing him shirtless? I can't believe what he does for
the cameras! Okay okay next question, what is your perfect date? Well it starts with a nice dinner at a delicious but small restaurant, you know
like one of those places where the owner is in the back and comes out to talk to you and ask you how your meal was. My favorite form of art?
Another hard one, but I think I'll have to go with music, music you can feel in your whole body and it is electrifying and best of all, you can
dance to it! Okay final question, let's see, What are three things you cannot live without? Well first off, my beautiful, beautiful cat Jerry, he is my
heart and spirit animal. Second is pasta, definitely pasta, and the third I think is my family, I love all of them very much and they support me in
everything I do. I know Jay Stacksby is a handsome man and all of us want to be the first to walk down the aisle with him, but I think he might
truly be the one for me. Okay that's it for the bio, I hope you have fun watching the show!"""

myrtle_beech_intro = """Salutations. My name? Myrtle. Myrtle Beech. I am a woman of simple tastes. I enjoy reading, thinking, and doing my taxes. I entered
this competition because I want a serious relationship. I want a commitment. The last man I dated was too whimsical. He wanted to go on dates
that had no plan. No end goal. Sometimes we would just end up wandering the streets after dinner. He called it a \"walk\". A \"walk\" with no
destination. Can you imagine? I like every action I take to have a measurable effect. When I see a movie, I like to walk away with insights that I
did not have before. When I take a bike ride, there better be a worthy destination at the end of the bike path. Jay seems frivolous at times. This
worries me. However, it is my staunch belief that one does not make and keep money without having a modicum of discipline. As such, I am
hopeful. I will now list three things I cannot live without. Water. Emery boards. Dogs. Thank you for the opportunity to introduce myself. I look
forward to the competition."""

gregg_t_fishy_intro ="""A good day to you all, I am Gregg T Fishy, of the Fishy Enterprise fortune. I am 37 years young. An adventurous spirit and I've never lost my
sense of childlike wonder. I do love to be in the backyard gardening and I have the most extraordinary time when I'm fishing. Fishing for what,
you might ask? Why, fishing for compliments of course! I have a stunning pair of radiant blue eyes. They will pierce the soul of anyone who
dare gaze upon my countenance. I quite enjoy going on long jaunts through garden paths and short walks through greenhouses. I hope that
Jay will be as absolutely interesting as he appears on the television. I find that he has some of the most curious tastes in style and humor.
When I'm out and about I quite enjoy hearing tales that instill in my heart of hearts the fascination that beguiles my every day life. Every fiber of
my being scintillates and vascillates with extreme pleasure during one of these charming anecdotes and significantly pleases my beautiful
personage. I cannot wait to enjoy being on A Brand New Jay. It certainly seems like a grand time to explore life and love."""

def get_average_sentence_length(text):
    
    sent_length = []
    
    punctuation = ".,?'!"
    
    Expected_Words =""
    
    
    for letter in text:
        if letter not in punctuation:
            Expected_Words += letter
            
    #print(Expected_Words) - Testing code by printing words w/o punctuation to get count of words

    letters_sentences = Expected_Words.split('\n')
    #print(letters_sentences) - Testing code by splitting string into a list of all sentences
    word_count_list = len(Expected_Words.split())
    #print(sentence_list) - Testing code by gicing total lenght of the words list which ultimately provides total word count
    
    #Code below will provide total number of sentences in note
    for sentences in letters_sentences:
        sent_length.append(len(sentences))
        
    #print(sent_length) - Testing list that inclundes all sentences to be used below to divide all words by number of sentences
            
    #Final formula - Total words divided by total number of sentences 
    avg_sntnce_len = word_count_list/len(sent_length)
    return avg_sntnce_len
    
#get_average_sentence_length(lily_trebuchet_intro)# - testing code

def prepare_text(text):
    
    punctuation = ".,?'!"
    
    Expected_Words =""
    
    
    for letter in text:
        if letter not in punctuation:
            Expected_Words += letter
            
    print(Expected_Words)
            
    lowercase_text =  Expected_Words.lower()
    Expected_list = lowercase_text.split()
       
    return Expected_list

#prepare_text ("Where did you go, friend? We nearly saw each other.") #- Testing code

def build_frequency_table(corpus):
    # not sure why the word "do" doesnt show up in  your example... The word do is an element of the list corpus #
    
    expected_dict = {}
    
    for element in corpus:
        expected_dict[element] = corpus.count(element)
    return expected_dict 
        
#print(build_frequency_table(['do', 'you', 'see', 'what', 'i', 'see'])) #- testing code

#print(build_frequency_table(['lets', 'check', 'other', 'code', 'lets', 'check'])) - testing code

def ngram_creator (text_list):
    
    n_gram_list = []
    
    for element in range(len(text_list) - 1):
        n_gram_list.append(text_list[element] + ' ' + text_list[element +1])
    
    
    return n_gram_list

#ngram_creator(['what', 'in', 'the', 'world', 'is', 'going', 'on']) - Testing code

class TextSample:
    
    def __init__(self,text,author):
        self.raw_text = text
        self.author = author
        self.average_sentence_length = get_average_sentence_length(text)
        self.prepare_text = prepare_text(text)
        self.word_count_frequency = build_frequency_table(text)
        self.ngram_frequency = build_frequency_table(ngram_creator(text))
    
    #get_average_sentence_length(self.raw.text) = self.average_sentence_length
    
    def __repr__(self):
        return self.author

def frequency_comparison (table1,table2):
    
    appearances = 0
    mutual_appearances = 0
    
    for key in table1.keys():
        if key in table2.keys():
            if table1[key] < table2[key]:
                mutual_appearances += table1[key]
                appearances += table2[key]
            elif table2[key] < table1[key]:
                mutual_appearances += table2[key]
                appearances += table1[key]
        else:
            appearances += table1[key]
            
    for key in table2.keys():
        if key not in table1.keys():
            appearances += table2[key]
     
    #print(appearances) testing...
    #print(mutual_appearances) testing...
    
    frequency_comparison_score = mutual_appearances/appearances
    
    return frequency_comparison_score
    
            
#print(frequency_comparison({'do': 1, 'you': 1, 'see': 2, 'what': 1, 'i': 1},{'lets': 2, 'do': 3, 'other': 1, 'code': 1})) - testing code             
            
murderer_sample = TextSample(murder_note,"Murderer")
lily_sample = TextSample(lily_trebuchet_intro,"Lily Trebuchet")
print(lily_sample.author)
myrtle_sample = TextSample(myrtle_beech_intro,"Myrtle Beech")
print(myrtle_sample)
gregg_sample = TextSample(gregg_t_fishy_intro,"Gregg T Fishy")
print(gregg_sample)  

def percent_difference(value1,value2):
    
    numerator = abs(value1 - value2)
    #print(numerator)
    
    denominator = (value1 + value2)/2
    #print(denominator)
    
    result = numerator/denominator
    #print(result)
    
    return result

#percent_difference(5,10) - Testing code

def find_text_similarity(TextSample1,TextSample2):
    
    TextSample1_sent_l_1 = get_average_sentence_length(TextSample1)
    #print(TextSample1_sent_l_1)
   
    TextSample2_sent_l_2 = get_average_sentence_length(TextSample2)
    #print(TextSample2_sent_l_2)
    
    sentence_length_difference = percent_difference(TextSample1_sent_l_1,TextSample2_sent_l_2)
    #print(sentence_length_difference)
    
    sentence_length_similarity = abs(1 - sentence_length_difference)
    #print(sentence_length_similarity)
    #End of first calculation, the result sentence_length_similarity will be added to remaining two.
    
    freq_TextSample1 = build_frequency_table(TextSample1)
    #print(freq_TextSample1)
    
    freq_TextSample2 = build_frequency_table(TextSample2)
    #print(freq_TextSample2)
    
    word_count_similarity = frequency_comparison(freq_TextSample1,freq_TextSample2)
    #print(word_count_similarity)
    #End of second calculation, the result sentence_length_similarity will be added to last one.
    
    ngram1 = ngram_creator(TextSample1)
    ngram_freq1 = build_frequency_table(ngram1)
    #print(ngram_freq1)
    ngram2 = ngram_creator(TextSample2)
    ngram_freq2 = build_frequency_table(ngram2)
    #print(ngram_freq2)
    
    ngram_similarity = frequency_comparison(ngram_freq1,ngram_freq2)
    #print(ngram_similarity)
    #End of third calculation
    
    return (sentence_length_similarity+word_count_similarity+ngram_similarity)/3

#find_text_similarity(lily_trebuchet_intro,murder_note)

print(lily_sample)
print(find_text_similarity(lily_trebuchet_intro,murder_note))
print(myrtle_sample)
print(find_text_similarity(myrtle_beech_intro,murder_note))
print(gregg_sample)
print(find_text_similarity(gregg_t_fishy_intro,murder_note))

#Lily Trebuchet
#0.7433163633205577
#Myrtle Beech
#0.6245223693863388
#Gregg T Fishy
#0.6772000926843931

#Who dunnit? Lily Trebuchet




 

        




